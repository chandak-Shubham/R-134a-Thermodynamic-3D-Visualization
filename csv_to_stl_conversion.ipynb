{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "53unOBvdEThK",
        "outputId": "5a6af81f-410d-4334-b37b-173ae22798c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy-stl\n",
            "  Downloading numpy_stl-3.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from numpy-stl) (2.0.2)\n",
            "Requirement already satisfied: python-utils>=3.4.5 in /usr/local/lib/python3.12/dist-packages (from numpy-stl) (3.9.1)\n",
            "Requirement already satisfied: typing_extensions>3.10.0.2 in /usr/local/lib/python3.12/dist-packages (from python-utils>=3.4.5->numpy-stl) (4.15.0)\n",
            "Downloading numpy_stl-3.2.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: numpy-stl\n",
            "Successfully installed numpy-stl-3.2.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'R134a_PVT_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2448952498.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Load and clean the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pressure_Pa'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Temperature_K'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SpecificVolume_m3_per_kg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'R134a_PVT_data.csv'"
          ]
        }
      ],
      "source": [
        "!pip install numpy-stl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from stl import mesh\n",
        "\n",
        "# Config section\n",
        "CSV_PATH = \"R134a_PVT_data.csv\"       # path to input data file\n",
        "OUT_STL = \"R134a_PvT_Surface.stl\"     # output STL file name\n",
        "\n",
        "# Choose which logarithm to use\n",
        "log_fn = np.log      # use np.log10 if you want base-10 logarithm\n",
        "\n",
        "# Load and clean the data\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df = df.dropna(subset=['Pressure_Pa', 'Temperature_K', 'SpecificVolume_m3_per_kg'])\n",
        "if df.empty:\n",
        "    raise SystemExit(\"No valid data after dropping NaNs.\")\n",
        "\n",
        "# Compute transformed axes\n",
        "df['log_v'] = log_fn(df['SpecificVolume_m3_per_kg'].astype(float))\n",
        "df['log_p'] = log_fn(df['Pressure_Pa'].astype(float))\n",
        "df['T'] = df['Temperature_K'].astype(float)\n",
        "\n",
        "# Round for stable grouping\n",
        "df['log_v_r'] = df['log_v'].round(12)\n",
        "df['T_r'] = df['T'].round(9)\n",
        "\n",
        "# Build grid from unique values (expected for evenly sampled surface)\n",
        "unique_v = np.sort(df['log_v_r'].unique())\n",
        "unique_T = np.sort(df['T_r'].unique())\n",
        "n_v = unique_v.size\n",
        "n_T = unique_T.size\n",
        "\n",
        "# If the data forms a complete grid, use it directly; otherwise, use nearest-neighbor binning\n",
        "if n_v * n_T == len(df):\n",
        "    mapping = df.set_index(['T_r', 'log_v_r'])['log_p'].to_dict()\n",
        "    Z = np.full((n_T, n_v), np.nan, dtype=float)\n",
        "    for i, Tval in enumerate(unique_T):\n",
        "        for j, vval in enumerate(unique_v):\n",
        "            Z[i, j] = mapping.get((Tval, vval), np.nan)\n",
        "else:\n",
        "    print(\"Warning: data not a perfect grid — performing nearest-neighbor binning.\")\n",
        "    n = int(np.sqrt(len(df)))\n",
        "    n_T = n_v = n if n > 1 else max(n_T, n_v, 2)\n",
        "    grid_v = np.linspace(df['log_v'].min(), df['log_v'].max(), n_v)\n",
        "    grid_T = np.linspace(df['T'].min(), df['T'].max(), n_T)\n",
        "    Z = np.full((n_T, n_v), np.nan, dtype=float)\n",
        "    idx_v = np.searchsorted(grid_v, df['log_v'].values, side='left')\n",
        "    idx_T = np.searchsorted(grid_T, df['T'].values, side='left')\n",
        "    idx_v = np.clip(idx_v, 0, n_v-1)\n",
        "    idx_T = np.clip(idx_T, 0, n_T-1)\n",
        "    count = np.zeros_like(Z)\n",
        "    sumZ = np.zeros_like(Z)\n",
        "    for k, (iv, it) in enumerate(zip(idx_v, idx_T)):\n",
        "        sumZ[it, iv] += df['log_p'].iat[k]\n",
        "        count[it, iv] += 1\n",
        "    mask = count > 0\n",
        "    Z[mask] = sumZ[mask] / count[mask]\n",
        "\n",
        "# Scale the axes (X, Y, Z) to a 0–100 range for easier 3D printing\n",
        "X_raw = unique_v if (n_v * n_T == len(df)) else np.linspace(df['log_v'].min(), df['log_v'].max(), n_v)\n",
        "Y_raw = unique_T if (n_v * n_T == len(df)) else np.linspace(df['T'].min(), df['T'].max(), n_T)\n",
        "Z_raw = Z\n",
        "\n",
        "nan_ratio = np.isnan(Z_raw).sum() / Z_raw.size\n",
        "if nan_ratio > 0.3:\n",
        "    print(f\"Warning: {nan_ratio*100:.1f}% of grid cells are empty; STL will skip those areas.\")\n",
        "\n",
        "def scale_to_0_100(arr):\n",
        "    arr = np.asarray(arr, dtype=float)\n",
        "    mn, mx = np.nanmin(arr), np.nanmax(arr)\n",
        "    if np.isclose(mn, mx):\n",
        "        return np.zeros_like(arr, dtype=float) + 50.0\n",
        "    return (arr - mn) / (mx - mn) * 100.0\n",
        "\n",
        "X = scale_to_0_100(X_raw)\n",
        "Y = scale_to_0_100(Y_raw)\n",
        "Zs = scale_to_0_100(Z_raw)\n",
        "\n",
        "# Build triangular faces (two triangles per grid cell)\n",
        "verts = []\n",
        "faces = []\n",
        "vertex_indices = -np.ones((n_T, n_v), dtype=int)\n",
        "\n",
        "for i in range(n_T):\n",
        "    for j in range(n_v):\n",
        "        if np.isnan(Zs[i, j]):\n",
        "            continue\n",
        "        vtx = [float(X[j]), float(Y[i]), float(Zs[i, j])]\n",
        "        vertex_indices[i, j] = len(verts)\n",
        "        verts.append(vtx)\n",
        "\n",
        "for i in range(n_T - 1):\n",
        "    for j in range(n_v - 1):\n",
        "        a = vertex_indices[i, j]\n",
        "        b = vertex_indices[i+1, j]\n",
        "        c = vertex_indices[i, j+1]\n",
        "        d = vertex_indices[i+1, j+1]\n",
        "        if a < 0 or b < 0 or c < 0 or d < 0:\n",
        "            continue\n",
        "        faces.append([a, b, c])\n",
        "        faces.append([b, d, c])\n",
        "\n",
        "if len(faces) == 0:\n",
        "    raise SystemExit(\"No faces generated: check input data and gridding.\")\n",
        "\n",
        "# Build numpy arrays for STL output\n",
        "verts_np = np.array(verts, dtype=float)\n",
        "faces_np = np.array(faces, dtype=int)\n",
        "\n",
        "# Create the STL mesh\n",
        "model = mesh.Mesh(np.zeros(faces_np.shape[0], dtype=mesh.Mesh.dtype))\n",
        "for i_face, (ia, ib, ic) in enumerate(faces_np):\n",
        "    model.vectors[i_face][0] = verts_np[ia]\n",
        "    model.vectors[i_face][1] = verts_np[ib]\n",
        "    model.vectors[i_face][2] = verts_np[ic]\n",
        "\n",
        "# Save the STL file\n",
        "model.save(OUT_STL)\n",
        "print(f\"STL saved to: {OUT_STL}\")\n",
        "print(f\"Grid: n_v={n_v}, n_T={n_T}, vertices={len(verts)}, faces={len(faces)}\")\n"
      ]
    }
  ]
}